{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coleta e limpeza de Dados Semi-estruturados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Importa a biblioteca Pandas, usada para manipulação e análise de dados.\n",
    "import json # Importa a biblioteca json, usada para manipulação de dados JSON.\n",
    "import xml.etree.ElementTree as ET # Importa a biblioteca xml.etree.ElementTree, usada para manipulação de dados XML.\n",
    "import requests # Importa a biblioteca requests, usada para realizar requisições HTTP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = 'https://jsonplaceholder.typicode.com/users' # URL da API de citações.\n",
    "response = requests.get(api_url) # Fazendo a requisição HTTP.\n",
    "data = response.json() # Converte a resposta JSON para um dicionário.\n",
    "df_json = pd.DataFrame(data) # Criando um DataFrame a partir do dicionário.\n",
    "\n",
    "df_json_normal = pd.json_normalize(data) # Normalizando o DataFrame para facilitar a visualização.\n",
    "\n",
    "df_json\n",
    "df_json_normal\n",
    "df_json_normal.info() # Exibindo informações sobre o DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested = {\n",
    "    'nome': 'x',\n",
    "    'email': 'lindo@gmail.com',\n",
    "    'addrress': {\n",
    "        'rua': 'Rua de Casa',\n",
    "        'cidade': 'Santo André',\n",
    "        'estado': 'UF',\n",
    "        'cep': '12345678'\n",
    "    } \n",
    "}\n",
    "\n",
    "df = pd.json_normalize(nested)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json['company'] = None # Criando uma nova coluna com dados de empresa.\n",
    "df_fil = df_json.fillna('Não Preenchido', inplace=True) # Preenchendo colunas com dados ausentes com um valor específico.\n",
    "df_fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json['company'] = None # Criando uma nova coluna com dados de empresa.\n",
    "df_drop = df_json.dropna(axis=1) # Removendo colunas com dados ausentes.\n",
    "df_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json_exploded = df_json.explode('address') # Explodindo a coluna 'address' em uma nova coluna para cada item do endereço.\n",
    "df_json_exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_data = \"\"\"\n",
    "<data>\n",
    "    <user>\n",
    "        <name>joao</name>\n",
    "        <email>joao@gmail.com</email>\n",
    "        <cidade>santo andre</cidade>\n",
    "    </user>\n",
    "    <user>\n",
    "        <name>maria</name>\n",
    "        <email>maria@gmail.com</email>\n",
    "        <cidade>sao paulo</cidade>\n",
    "    </user>\n",
    "</data>\n",
    "\"\"\"\n",
    "\n",
    "root = ET.fromstring(xml_data) # Criando um objeto ElementTree a partir do XML.\t\n",
    "users = [] # Lista para armazenar os dados dos usuários.\t\n",
    "\n",
    "for user in root.findall(\"user\"): # Iterando sobre cada elemento 'user' do XML.\t\n",
    "    users.append({ # Criando um dicionário com os dados do usuário.\t\n",
    "        'name':user.find('name').text if user.find('name') is not None else None,\n",
    "        'email':user.find('email').text if user.find('email') is not None else None,\n",
    "        'cidade':user.find('cidade').text if user.find('cidade') is not None else None\n",
    "\n",
    "    })\n",
    "\n",
    "df_xml = pd.DataFrame(users) # Criando um DataFrame a partir dos dados dos usuários.\t\n",
    "df_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dups = pd.DataFrame({'id': [1, 1, 3, 4], 'nome': ['Alan', 'Alan', 'Brenda', 'Aurora Flor']}) # DataFrame com dados duplicados.\n",
    "print('Antes') \n",
    "print(df_dups)\n",
    "\n",
    "df_unico = df_dups.drop_duplicates() # Removendo dados duplicados.\n",
    "\n",
    "print('Depois')\n",
    "\n",
    "print(df_unico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_padrao = pd.DataFrame({'datas': ['2022-01-01', 'feb 24, 2024', '2022-01-03', '12-01-2024']}) # DataFrame com dados incorretos de data.\n",
    "\n",
    "df_padrao['datas'] = pd.to_datetime(df_padrao['datas'], format='mixed') # Convertendo dados de data para o formato padrão.\n",
    "\n",
    "print(df_padrao) #  Exibindo o DataFrame com dados corrigidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'r', encoding='utf-8') as f: \n",
    "    data_arq = json.load(f)\n",
    "\n",
    "data_arq[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('chaves', data_arq[0].keys()) # Exibindo as chaves do primeiro elemento do JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp = pd.json_normalize(data_arq) # Normalizando o DataFrame para facilitar a visualização.\n",
    "df_yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelpcustom = pd.DataFrame([{\n",
    "    'business_id': d.get('business_id'),\n",
    "    'name': d.get('name'),\n",
    "    'city': d.get('city'),\n",
    "    'review_count': d.get('review_count'),\n",
    "    'stars': d.get('stars'),\n",
    "    'categories': d.get('categories')\n",
    "} for d in data_arq])\n",
    "print(df_yelpcustom.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelpcustom.fillna('Desconhecido', inplace=True) # Preenchendo colunas com dados ausentes com um valor específico.\n",
    "print(df_yelpcustom.info()) # Exibindo informações sobre o DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelpatri = pd.DataFrame([{\n",
    "     'business_id': d.get('business_id'), \n",
    "    'Wifi': (d.get('attributes') or {}).get('WiFi', 'Unknown'), # Busca o valor da chave 'WiFi' no dicionário 'attributes' ou usa 'Unknown' caso não seja encontrado.\n",
    "    'OutdoorSeating': (d.get('attributes') or {}).get('OutdoorSeating', 'Unknown'), # Busca o valor da chave 'OutdoorSeating' no dicionário 'attributes' ou usa 'Unknown' caso não seja encontrado.\n",
    "} for d in data_arq])\n",
    "\n",
    "print(df_yelpatri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arq[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'] # Dias da semana.\n",
    "\n",
    "df_horario = pd.DataFrame([{\n",
    "    'business_id': d.get('business_id'),\n",
    "    # Busca o horário para cada dia da semana no dicionário 'hours' ou usa 'Fechado' caso não seja encontrado.\n",
    "    **{day: (d.get('hours') or {} ).get(day, 'Fechado') for day in weekdays} \n",
    "} for d in data_arq])\n",
    "\n",
    "df_horario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo um merge left join entre os DataFrames df_yelpcustom e df_yelpatri.\n",
    "df_merge = df_yelpcustom.merge(df_yelpatri, on = 'business_id', how = 'left') \n",
    "\n",
    "# Fazendo um merge left join entre o resultado anterior e df_horario.\n",
    "df_merge = df_merge.merge(df_horario, on = 'business_id', how = 'left') \n",
    "\n",
    "df_merge.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_explode = df_merge.assign(categories = df_merge['categories'].str.split(', ')) # Explodindo a coluna 'categories' em uma nova coluna para cada item da lista.\n",
    "df_merge_explode = df_merge_explode.explode('categories') # Reindexando o DataFrame para eliminar as linhas duplicadas.\n",
    "df_merge_explode.head(10) # Exibindo as primeiras 10 linhas do DataFrame.\n",
    "len(df_merge_explode) # Exibindo o número de restaurantes no DataFrame.\n",
    "\n",
    "df_restaurantes = df_merge_explode[df_merge_explode['categories'] == 'Restaurants'] # Filtrando os restaurantes.\n",
    "len(df_restaurantes) # Exibindo o número de restaurantes no DataFrame."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
